{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1517ee03-b6ae-41bd-980d-604f675602e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.10/site-packages (from datasets) (1.26.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/miniconda3/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.12.2)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.7.1)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/miniconda3/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, tqdm, requests, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.2\n",
      "    Uninstalling huggingface-hub-0.20.2:\n",
      "      Successfully uninstalled huggingface-hub-0.20.2\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.9 aiosignal-1.3.1 async-timeout-5.0.1 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 huggingface-hub-0.26.3 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 pyarrow-18.1.0 requests-2.32.3 tqdm-4.67.1 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e46573b-d736-4325-bf02-55c2dc854786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/lib/python3.10/site-packages (4.36.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.0\n",
      "    Uninstalling tokenizers-0.15.0:\n",
      "      Successfully uninstalled tokenizers-0.15.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.36.2\n",
      "    Uninstalling transformers-4.36.2:\n",
      "      Successfully uninstalled transformers-4.36.2\n",
      "Successfully installed tokenizers-0.20.3 transformers-4.46.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcc39ee-9621-47ca-82ee-ee366fe41529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6167ba72-8362-48bd-83a4-1331b650183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "Successfully installed protobuf-5.29.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680745e6-cbe8-4c7e-8e65-ec4f8e7b9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d52aa59-d42e-4bd4-8086-bb780ffdf1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'meta-llama/Llama-3.1-8B'\n",
    "token = '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'\n",
    "single_precision = True\n",
    "gpu_id = 0\n",
    "classes = ['negative', 'positive']\n",
    "class_labels = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "# Updated prompt templates\n",
    "prompts = [\n",
    "    \"Given the following text, does the sentiment lean more towards being positive or negative? Analyze the text carefully before answering.\\nText: {}\\nSentiment:\",\n",
    "    \"What is the emotional sentiment conveyed by the following text? Indicate if it reflects a positive or negative sentiment.\\nText: {}\\nSentiment:\",\n",
    "    \"Is the sentiment in this text generally favorable or unfavorable? Please provide your answer based on the tone of the text.\\nText: {}\\nSentiment:\",\n",
    "    \"Does the following sentence express positive or negative opinion?\\nText: {}\\nSentiment:\",\n",
    "    \"Classify the sentiment of the following sentence as either positive or negative.\\nText: {}\\nSentiment:\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43286f89-c9f4-4899-a560-b4a36bc88749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:3479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3a0cd3d08249f19df6a1ae469bb300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "# Set device and seed\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.cuda.set_device(gpu_id)\n",
    "device = torch.device(f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "# Load model and tokenizer\n",
    "def load_model_tokenizer(model_name, single_precision, token):\n",
    "    model = LlamaForCausalLM.from_pretrained(model_name,\n",
    "                                             cache_dir=\"cache/\",\n",
    "                                             torch_dtype=torch.float16 if single_precision else torch.float32,\n",
    "                                             use_auth_token=token)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                              cache_dir=\"cache/\",\n",
    "                                              use_auth_token=token,\n",
    "                                              padding_side=\"left\")\n",
    "    tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_model_tokenizer(model_name, single_precision, token)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Get the token indices for the class labels \"positive\" and \"negative\"\n",
    "class_idx = {\n",
    "    0: tokenizer.encode(\"negative\", add_special_tokens=False)[0],\n",
    "    1: tokenizer.encode(\"positive\", add_special_tokens=False)[0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e6dcf8-7a85-4819-9aa9-c29789928a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            content\n",
      "0      0     no movement , no yuks , not much of anything .\n",
      "1      0  a gob of drivel so sickly sweet , even the eag...\n",
      "2      0  gangs of new york is an unapologetic mess , wh...\n",
      "3      0  we never really feel involved with the story ,...\n",
      "4      1            this is one of polanski 's best films .\n"
     ]
    }
   ],
   "source": [
    "test_file_path = \"data/test.tsv\"\n",
    "\n",
    "# Read the TSV file with the correct delimiter\n",
    "test_data = pd.read_csv(test_file_path, sep='\\t')\n",
    "\n",
    "# Check the data structure\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5371facd-38e6-4735-bfd3-6534849de8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            content\n",
      "0      0                       one long string of cliches .\n",
      "1      0  if you 've ever entertained the notion of doin...\n",
      "2      0  k-19 exploits our substantial collective fear ...\n",
      "3      0  it 's played in the most straight-faced fashio...\n",
      "4      1  there is a fabric of complex ideas here , and ...\n"
     ]
    }
   ],
   "source": [
    "dev_file_path = \"data/dev.tsv\"\n",
    "\n",
    "# Read the TSV file with the correct delimiter\n",
    "dev_data = pd.read_csv(dev_file_path, sep='\\t')\n",
    "\n",
    "# Check the data structure\n",
    "print(dev_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69147d40-9146-472a-a375-a83ec38ec022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                           sentence\n",
      "0      0        hide new secretions from the parental units\n",
      "1      0                contains no wit , only labored gags\n",
      "2      1  that loves its characters and communicates som...\n",
      "3      0  remains utterly satisfied to remain the same t...\n",
      "4      0  on the worst revenge-of-the-nerds clichés the ...\n"
     ]
    }
   ],
   "source": [
    "train_file_path = \"data/train.tsv\"\n",
    "\n",
    "# Read the TSV file with the correct delimiter\n",
    "train_data = pd.read_csv(train_file_path, sep='\\t')\n",
    "\n",
    "# Check the data structure\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aca920d-9419-4b45-96cf-1d323269c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_Mexample(sentence,label, prompt_template, maps, curr_prompt, curr_sentence):\n",
    "    # Format the prompt with the review text\n",
    "\n",
    "    prompt_text = prompt_template.format(sentence)\n",
    "\n",
    "    # Encode the prompt and truncate to fit model's max length\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\", padding='longest', truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # Extract the logits for the last token and apply softmax for binary classification\n",
    "    last_token_logits = logits[:, -1, [class_idx[0], class_idx[1]]]\n",
    "    probs = torch.softmax(last_token_logits, dim=-1)\n",
    "\n",
    "    # Get predicted class (0 = negative, 1 = positive)\n",
    "    predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "    if predicted_class == label:\n",
    "        if maps[curr_sentence]['confidence'] < abs(probs[0][predicted_class].item() - 0.5):\n",
    "            maps[curr_sentence]['confidence'] = abs(probs[0][predicted_class].item() - 0.5)\n",
    "            maps[curr_sentence]['prompt'] = curr_prompt\n",
    "    else :\n",
    "        if maps[curr_sentence]['prompt'] == -1:\n",
    "            maps[curr_sentence]['prompt'] = curr_prompt\n",
    "            maps[curr_sentence]['confidence'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3b39ff-a747-47bc-8975-9fb54d7e4f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using prompt: Given the following text, does the sentiment lean more towards being positive or negative? Analyze the text carefully before answering.\n",
      "Text: {}\n",
      "Sentiment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67349/67349 [50:38<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using prompt: What is the emotional sentiment conveyed by the following text? Indicate if it reflects a positive or negative sentiment.\n",
      "Text: {}\n",
      "Sentiment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67349/67349 [51:10<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using prompt: Is the sentiment in this text generally favorable or unfavorable? Please provide your answer based on the tone of the text.\n",
      "Text: {}\n",
      "Sentiment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67349/67349 [51:17<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using prompt: Does the following sentence express positive or negative opinion?\n",
      "Text: {}\n",
      "Sentiment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67349/67349 [49:49<00:00, 22.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating using prompt: Classify the sentiment of the following sentence as either positive or negative.\n",
      "Text: {}\n",
      "Sentiment:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67349/67349 [50:17<00:00, 22.32it/s]\n"
     ]
    }
   ],
   "source": [
    "maps = {key: {\"confidence\": 0, \"prompt\": -1} for key in range(len(train_data[\"sentence\"]))}\n",
    "curr_prompt = 0\n",
    "for prompt_template in prompts:\n",
    "    print(f\"Evaluating using prompt: {prompt_template}\")\n",
    "    curr_sentence = 0\n",
    "    \n",
    "    for sentence in tqdm(train_data[\"sentence\"]):\n",
    "        classify_Mexample(sentence,train_data[\"label\"][curr_sentence], prompt_template, maps, curr_prompt, curr_sentence) \n",
    "        curr_sentence += 1 \n",
    "        \n",
    "    curr_prompt += 1 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff06f53-000b-43c8-96ff-e2cdba962f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidenceMethod(sentence, prompt_template, curr_sentence, maps):\n",
    "    prompt_temp = prompt_template[maps[curr_sentence]['prompt']]\n",
    "    prompt_text = prompt_temp.format(sentence)\n",
    "    \n",
    "    # Encode the prompt and truncate to fit model's max length\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\", padding='longest', truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # Extract the logits for the last token and apply softmax for binary classification\n",
    "    last_token_logits = logits[:, -1, [class_idx[0], class_idx[1]]]\n",
    "    probs = torch.softmax(last_token_logits, dim=-1)\n",
    "    \n",
    "    # Get predicted class (0 = negative, 1 = positive)\n",
    "    predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "    \n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e070da-39c8-4bb4-8212-31793269837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67349/67349 [50:34<00:00, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for Confidence method:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9993    0.5691    0.7252     29780\n",
      "    positive     0.7453    0.9997    0.8540     37569\n",
      "\n",
      "    accuracy                         0.8093     67349\n",
      "   macro avg     0.8723    0.7844    0.7896     67349\n",
      "weighted avg     0.8576    0.8093    0.7970     67349\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = train_data[\"label\"]  # Ground truth labels\n",
    "curr_sentence = 0\n",
    "data = {\n",
    "    \"statement\": [],\n",
    "    \"prompt\": []\n",
    "}\n",
    "\n",
    "for sentence in tqdm(train_data[\"sentence\"]):\n",
    "    data[\"statement\"].append(sentence)\n",
    "    data[\"prompt\"].append(maps[curr_sentence]['prompt'])\n",
    "    pred = confidenceMethod(sentence, prompts, curr_sentence, maps)\n",
    "    curr_sentence += 1\n",
    "    all_preds.append(pred)\n",
    "print(\"Evaluation Metrics for Confidence method:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"negative\", \"positive\"], digits=4))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e2597-54ec-44d5-9930-8b0702f6d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = test_data[\"label\"]  # Ground truth labels\n",
    "curr_sentence = 0\n",
    "data = {\n",
    "    \"statement\": [],\n",
    "    \"prompt\": []\n",
    "}\n",
    "\n",
    "for sentence in tqdm(test_data[\"content\"]):\n",
    "    data[\"statement\"].append(sentence)\n",
    "    data[\"prompt\"].append(maps[curr_sentence]['prompt'])\n",
    "    pred = confidenceMethod(sentence, prompts, curr_sentence, maps)\n",
    "    curr_sentence += 1\n",
    "    all_preds.append(pred)\n",
    "print(\"Evaluation Metrics for Confidence method:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"negative\", \"positive\"], digits=4))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ad4428c-2a26-4d31-af4b-ddc210289cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17dbcff4-768a-4297-91ef-6fb457100b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5124721603563475\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.62      0.55      3626\n",
      "           1       0.52      0.66      0.58      4391\n",
      "           2       0.55      0.30      0.38      1267\n",
      "           3       0.53      0.43      0.47      2823\n",
      "           4       0.43      0.11      0.18      1363\n",
      "\n",
      "    accuracy                           0.51     13470\n",
      "   macro avg       0.51      0.42      0.43     13470\n",
      "weighted avg       0.51      0.51      0.49     13470\n",
      "\n",
      "Statement: 'I think the actor could have done a better job, overall the stroy was good.' => Predicted Prompt: 1\n",
      "Statement: 'The screenplay was done right and it has perfect climax.' => Predicted Prompt: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "X = df[\"statement\"]\n",
    "y = df[\"prompt\"].values\n",
    "\n",
    "# Convert text into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# 2. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train Logistic Regression Model\n",
    "Lmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "Lmodel.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate Model\n",
    "y_pred = Lmodel.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 5. Prediction for New Statements\n",
    "new_statements = [\"I think the actor could have done a better job, overall the stroy was good.\", \"The screenplay was done right and it has perfect climax.\"]\n",
    "new_statements_vectorized = vectorizer.transform(new_statements)\n",
    "predictions = Lmodel.predict(new_statements_vectorized)\n",
    "\n",
    "for statement, pred in zip(new_statements, predictions):\n",
    "    print(f\"Statement: '{statement}' => Predicted Prompt: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "449310b5-078c-4707-8afc-b6fb6b24163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalPrediction(sentence, Lmodel, label, y_probs):\n",
    "    new_statements_vectorized = vectorizer.transform(sentence)\n",
    "    predictions = Lmodel.predict(new_statements_vectorized)\n",
    "    prompt_template = prompts[predictions[0]]\n",
    "    prompt_text = prompt_template.format(sentence[0])\n",
    "    \n",
    "    # Encode the prompt and truncate to fit model's max length\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\", padding='longest', truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # Extract the logits for the last token and apply softmax for binary classification\n",
    "    last_token_logits = logits[:, -1, [class_idx[0], class_idx[1]]]\n",
    "    probs = torch.softmax(last_token_logits, dim=-1)\n",
    "    \n",
    "    # Get predicted class (0 = negative, 1 = positive)\n",
    "    predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "    y_probs.append(probs[0][label].item())\n",
    "    return predicted_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "137c539f-ecb1-4b3a-b7e7-5c2525261ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1821/1821 [01:16<00:00, 23.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for the current prompt:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.9852    0.5121    0.6739       912\n",
      "    positive     0.6696    0.9923    0.7996       909\n",
      "\n",
      "    accuracy                         0.7518      1821\n",
      "   macro avg     0.8274    0.7522    0.7368      1821\n",
      "weighted avg     0.8277    0.7518    0.7367      1821\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = test_data[\"label\"]  # Ground truth labels\n",
    "curr_sentence = 0\n",
    "y_probs = []\n",
    "for sentence in tqdm(test_data[\"content\"]):\n",
    "    pred = FinalPrediction([sentence], Lmodel, test_data[\"label\"][curr_sentence], y_probs) \n",
    "    curr_sentence = curr_sentence + 1\n",
    "    all_preds.append(pred)\n",
    "\n",
    "print(\"Evaluation Metrics for the current prompt:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"negative\", \"positive\"], digits=4))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf44ac-0ed3-469a-9e75-2524a6d0909e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4bc05-aaa4-4ac3-b046-055606894ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
